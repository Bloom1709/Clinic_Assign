{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYp0njP6XJXP"
   },
   "source": [
    "# ชื่อ : ณัฐกานต์\n",
    "# นามสกุล : ศิริพรโณ\n",
    "# รหัสนักศึกษา : 61070290\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUwCMbvAL09q"
   },
   "source": [
    "# Lab AI for Medicine : Heart Dataset\n",
    "ชุดข้อมูลโรคหัวใจ ประกอบด้วยฐานข้อมูล 4 ฐานข้อมูลเกี่ยวกับการวินิจฉัยโรคหัวใจ แอตทริบิวต์ทั้งหมดมีค่าเป็นตัวเลข ข้อมูลถูกรวบรวมจากไฟล์  4 สถานที่ดังต่อไปนี้:\n",
    "\n",
    "      1 มูลนิธิคลีฟแลนด์คลินิก (cleveland.data)\n",
    "      2 สถาบันโรคหัวใจแห่งฮังการีบูดาเปสต์ (Hungarian.data)\n",
    "      3 V.A. ศูนย์การแพทย์ลองบีชแคลิฟอร์เนีย (long-beach-va.data)\n",
    "      4 โรงพยาบาลมหาวิทยาลัยซูริกประเทศสวิตเซอร์แลนด์ (ข้อมูลสวิตเซอร์แลนด์)\n",
    "\n",
    "แต่ละฐานข้อมูลมีรูปแบบเดียวกัน ในขณะที่ฐานข้อมูลมี 76 แอตทริบิวต์ มีเพียง 14 รายการเท่านั้นที่ใช้จริง \n",
    "\n",
    "ข้อมูลโรคหัวใจชุดนี้มี 76 แอตทริบิวต์ ซึ่งมีรายละเอียดดังนี้ \n",
    "\n",
    "1 id: patient identification number\n",
    "\n",
    "2 ccf: social security number (I replaced this with a dummy value of 0)\n",
    "\n",
    "3 age: age in years\n",
    "\n",
    "4 sex: sex (1 = male; 0 = female)\n",
    "\n",
    "5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n",
    "\n",
    "6 painexer (1 = provoked by exertion; 0 = otherwise)\n",
    "\n",
    "7 relrest (1 = relieved after rest; 0 = otherwise)\n",
    "\n",
    "8 pncaden (sum of 5, 6, and 7)\n",
    "\n",
    "9 cp: chest pain type\n",
    "-- Value 1: typical angina\n",
    "-- Value 2: atypical angina\n",
    "-- Value 3: non-anginal pain\n",
    "-- Value 4: asymptomatic\n",
    "\n",
    "10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "\n",
    "11 htn\n",
    "\n",
    "12 chol: serum cholestoral in mg/dl\n",
    "\n",
    "13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n",
    "\n",
    "14 cigs (cigarettes per day)\n",
    "\n",
    "15 years (number of years as a smoker)\n",
    "\n",
    "16 fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "\n",
    "17 dm (1 = history of diabetes; 0 = no such history)\n",
    "\n",
    "18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n",
    "\n",
    "19 restecg: resting electrocardiographic results\n",
    "-- Value 0: normal\n",
    "-- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "-- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "\n",
    "20 ekgmo (month of exercise ECG reading)\n",
    "\n",
    "21 ekgday(day of exercise ECG reading)\n",
    "\n",
    "22 ekgyr (year of exercise ECG reading)\n",
    "\n",
    "23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n",
    "\n",
    "24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n",
    "\n",
    "25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n",
    "\n",
    "26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n",
    "\n",
    "27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n",
    "\n",
    "28 proto: exercise protocol\n",
    "  1 = Bruce\n",
    "  2 = Kottus\n",
    "  3 = McHenry\n",
    "  4 = fast Balke\n",
    "  5 = Balke\n",
    "  6 = Noughton\n",
    "  7 = bike 150 kpa min/min (Not sure if \"kpa min/min\" is what was written!)\n",
    "  8 = bike 125 kpa min/min\n",
    "  9 = bike 100 kpa min/min\n",
    "  10 = bike 75 kpa min/min\n",
    "  11 = bike 50 kpa min/min\n",
    "  12 = arm ergometer\n",
    "\n",
    "29 thaldur: duration of exercise test in minutes\n",
    "\n",
    "30 thaltime: time when ST measure depression was noted\n",
    "\n",
    "31 met: mets achieved\n",
    "\n",
    "32 thalach: maximum heart rate achieved\n",
    "\n",
    "33 thalrest: resting heart rate\n",
    "\n",
    "34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n",
    "\n",
    "35 tpeakbpd: peak exercise blood pressure (second of 2 \n",
    "parts)\n",
    "\n",
    "36 dummy\n",
    "\n",
    "37 trestbpd: resting blood pressure\n",
    "\n",
    "38 exang: exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "39 xhypo: (1 = yes; 0 = no)\n",
    "\n",
    "40 oldpeak = ST depression induced by exercise relative to rest\n",
    "\n",
    "41 slope: the slope of the peak exercise ST segment\n",
    "-- Value 1: upsloping\n",
    "-- Value 2: flat\n",
    "-- Value 3: downsloping\n",
    "\n",
    "42 rldv5: height at rest\n",
    "\n",
    "43 rldv5e: height at peak exercise\n",
    "\n",
    "44 ca: number of major vessels (0-3) colored by flourosopy\n",
    "\n",
    "45 restckm: irrelevant\n",
    "\n",
    "46 exerckm: irrelevant\n",
    "\n",
    "47 restef: rest raidonuclid (sp?) ejection fraction\n",
    "\n",
    "48 restwm: rest wall (sp?) motion abnormality\n",
    "  0 = none\n",
    "  1 = mild or moderate\n",
    "  2 = moderate or severe\n",
    "  3 = akinesis or dyskmem (sp?)\n",
    "\n",
    "49 exeref: exercise radinalid (sp?) ejection fraction\n",
    "\n",
    "50 exerwm: exercise wall (sp?) motion\n",
    "\n",
    "51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "\n",
    "52 thalsev: not used\n",
    "\n",
    "53 thalpul: not used\n",
    "\n",
    "54 earlobe: not used\n",
    "\n",
    "55 cmo: month of cardiac cath (sp?) (perhaps \"call\")\n",
    "\n",
    "56 cday: day of cardiac cath (sp?)\n",
    "\n",
    "57 cyr: year of cardiac cath (sp?)\n",
    "\n",
    "58 num: diagnosis of heart disease (angiographic disease status)\n",
    "-- Value 0: < 50% diameter narrowing\n",
    "-- Value 1: > 50% diameter narrowing\n",
    "(in any major vessel: attributes 59 through 68 are vessels)\n",
    "\n",
    "59 lmt\n",
    "\n",
    "60 ladprox\n",
    "\n",
    "61 laddist\n",
    "\n",
    "62 diag\n",
    "\n",
    "63 cxmain\n",
    "\n",
    "64 ramus\n",
    "\n",
    "65 om1\n",
    "\n",
    "66 om2\n",
    "\n",
    "67 rcaprox\n",
    "\n",
    "68 rcadist\n",
    "\n",
    "69 lvx1: not used\n",
    "\n",
    "70 lvx2: not used\n",
    "\n",
    "71 lvx3: not used\n",
    "\n",
    "72 lvx4: not used\n",
    "\n",
    "73 lvf: not used\n",
    "\n",
    "74 cathef: not used\n",
    "\n",
    "75 junk: not used\n",
    "\n",
    "76 name: last name of patient (I replaced this with the dummy string \"name\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8B0Goz4Shxd"
   },
   "source": [
    "จำนวนข้อมูลโรคหัวใจมีดังนี้ : \n",
    "  \n",
    "*   Cleveland     :     303 Records\n",
    "*   Hungarian     :     294 Records\n",
    "*   Switzerland   :     123 Records\n",
    "*   Long Beach VA :     200 Records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zusr5H3MTSAl"
   },
   "source": [
    "Attribute Information:\n",
    "   -- Only 14 used\n",
    "      \n",
    "      -- 1. #3  (age)       \n",
    "      -- 2. #4  (sex)       \n",
    "      -- 3. #9  (cp)        \n",
    "      -- 4. #10 (trestbps)  \n",
    "      -- 5. #12 (chol)      \n",
    "      -- 6. #16 (fbs)       \n",
    "      -- 7. #19 (restecg)   \n",
    "      -- 8. #32 (thalach)   \n",
    "      -- 9. #38 (exang)     \n",
    "      -- 10. #40 (oldpeak)   \n",
    "      -- 11. #41 (slope)     \n",
    "      -- 12. #44 (ca)        \n",
    "      -- 13. #51 (thal)      \n",
    "      -- 14. #58 (num)       (the predicted attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsJkzcFzNfT7"
   },
   "source": [
    "# วัตถุประสงค์"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61NaSUBxN3_n"
   },
   "source": [
    "โครงการนี้มีวัตถุประสงค์เพื่อช่วยให้ผู้เชี่ยวชาญด้านสุขภาพทำการวินิจฉัยได้ง่ายขึ้นโดยใช้เทคนิค Machine Learning เพื่อเป็นการเชื่อมกันระหว่างความรู้กับชุดข้อมูลที่ทำการบันทึกไว้สามารถนำไปใช้ประโยขน์ได้ ดังนั้นในการทดลองนี้เราจะนำเทคนิค Machine learning มาประยุกต์ใช้กับ Heart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.3.1-cp38-cp38-macosx_10_14_x86_64.whl (165.2 MB)\n",
      "\u001b[K     |██                              | 10.7 MB 8.8 kB/s eta 4:52:40\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 313, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1840, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1646, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 313, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1840, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1646, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 313, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1840, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1646, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 313, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1840, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1646, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 313, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1840, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1646, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 313, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1840, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/OpenSSL/SSL.py\", line 1646, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 425, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 507, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/http/client.py\", line 454, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/http/client.py\", line 498, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 328, in recv_into\n",
      "    return self.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 328, in recv_into\n",
      "    return self.recv_into(*args, **kwargs)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 328, in recv_into\n",
      "    return self.recv_into(*args, **kwargs)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 326, in recv_into\n",
      "    raise timeout(\"The read operation timed out\")\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/cli/base_command.py\", line 188, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/cli/req_command.py\", line 185, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/commands/install.py\", line 332, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\", line 179, in resolve\n",
      "    discovered_reqs.extend(self._resolve_one(requirement_set, req))\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\", line 362, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/resolution/legacy/resolver.py\", line 314, in _get_abstract_dist_for\n",
      "    abstract_dist = self.preparer.prepare_linked_requirement(req)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 467, in prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 255, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 129, in get_http_url\n",
      "    from_path, content_type = _download_http_url(\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/operations/prepare.py\", line 281, in _download_http_url\n",
      "    for chunk in download.chunks:\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/cli/progress_bars.py\", line 166, in iter\n",
      "    for x in it:\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_internal/network/utils.py\", line 15, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 564, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 529, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Users/blm/opt/anaconda3/lib/python3.8/site-packages/pip/_vendor/urllib3/response.py\", line 430, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEe83SPlOB2X"
   },
   "source": [
    "Import and Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uQ0bJY2pOHyM"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cf18d967fdc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as mod\n",
    "import sklearn.neighbors as nei\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report, precision_recall_curve, average_precision_score \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import operator\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2 as sklearn_chi2\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import h5py\n",
    "from sklearn.metrics import recall_score, precision_score,f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Heart_UCI_data/Processed_cleveland_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NMaOO-2OrG4"
   },
   "source": [
    "# Check Null Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jAGYiLxO0zW"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P81z6A7EOIZI"
   },
   "source": [
    "# ตรวจสอบข้อมูลเพื่อจัดการ Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "miss = []\n",
    "for i in range(14):\n",
    "    if '?' in df[columns[i]].value_counts():\n",
    "        miss.append(columns[i])\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(\"?\", np.NaN)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ca'] = df['Ca'].astype(\"int64\")\n",
    "df['Thal'] = df['Thal'].astype(\"int64\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjr4z2sjOS6A"
   },
   "source": [
    "# แสดง Attribute Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8iMQpf-OqMX"
   },
   "outputs": [],
   "source": [
    "df.iloc[:, :-1].hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# หา Correlation ของ Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(df_corr, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train- test split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train ,x_test, y_train, y_test = train_test_split(df.drop(\"Num_diagnosis\", axis=1 ), \n",
    "                                                                 df[\"Num_diagnosis\"], test_size=0.2, random_state= 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_eB7NrWO2lY"
   },
   "source": [
    "# Logistic Regression Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.LogisticRegression(solver='liblinear')\n",
    "acc_scores =  cross_val_score(model, df.drop(\"Num_diagnosis\", axis=1) , df[\"Num_diagnosis\"], cv=10, scoring=\"accuracy\")\n",
    "print(\"Logistic Regression: Mean cross-validation accuracy = %.2f\" % acc_scores.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iTolYQdPwhX"
   },
   "source": [
    "# k-NN with k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFJ8uvHSO9Wm"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(x_train, y_train)\n",
    "(knn.predict(x_test) == y_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn.predict(x_test)\n",
    "accuracy = metrics.accuracy_score(y_test, knn_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score (knn,  df.drop(\"Num_diagnosis\", axis=1) , df[\"Num_diagnosis\"], cv =10, scoring = 'accuracy')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mtx_knn = metrics.confusion_matrix(y_test, knn_pred)\n",
    "conf_mtx_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presicion & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrAbbeeJPFxA"
   },
   "source": [
    "# SVM Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f92_QQR5PIQn"
   },
   "outputs": [],
   "source": [
    "svm = SVC(C=2, gamma='scale', kernel='linear')\n",
    "svm.fit(x_train, y_train)\n",
    "svm_pred = svm.predict(x_test)\n",
    "print(metrics.accuracy_score(svm_pred, y_test) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ygJaTKaQSpV"
   },
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEq8l_ssQVU2"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, svm_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31MUpR-tQQF3"
   },
   "source": [
    "Presicion & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIqxT6myQRuN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puu_s7kqPIso"
   },
   "source": [
    "# Decision Tree Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5fQWg9iPMfX"
   },
   "outputs": [],
   "source": [
    "decitree = DecisionTreeClassifier()\n",
    "decitree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decitree_pred = decitree.predict(x_test)\n",
    "decitree_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iltosiFnQide"
   },
   "source": [
    "Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ji52lICjQidg"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, decitree_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waoVMh7gQidi"
   },
   "source": [
    "Presicion & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDSe8-leQidj"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, decitree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfraR_FXPNC4"
   },
   "source": [
    "# Neural Network (NN) Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1xazjp2PR5W"
   },
   "outputs": [],
   "source": [
    "NN = Sequential()\n",
    "\n",
    "NN.add(Dense(15 ,activation='relu',input_shape=(x_train_cl.shape[1:])))\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "NN.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNUuguP0Qjx-"
   },
   "source": [
    "Confustion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrogKAJaQjx_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8JIiLtsQjyB"
   },
   "source": [
    "Presicion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgGti7UrQjyC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubx4LS0EQjyE"
   },
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ou0nVmKOQjyF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU9FowWbQomf"
   },
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWXvdSroQ15Z"
   },
   "source": [
    "Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J., Sandhu, S., Guppy, K., Lee, S., & Froelicher, V. (1989). International application of a new probability algorithm for the diagnosis of coronary artery disease. American Journal of Cardiology, 64,304--310.\n",
    "[Web Link]\n",
    "\n",
    "David W. Aha & Dennis Kibler. \"Instance-based prediction of heart-disease presence with the Cleveland database.\"\n",
    "[Web Link]\n",
    "\n",
    "Gennari, J.H., Langley, P, & Fisher, D. (1989). Models of incremental concept formation. Artificial Intelligence, 40, 11--61.\n",
    "[Web Link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_TJrrrNQmYP"
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Heart_Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
